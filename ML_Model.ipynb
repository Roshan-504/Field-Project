{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a856e686-8f28-4177-b3f1-a152be6ba614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Roshan Yadav\\speciesnet-env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import requests  # For sending HTTP alerts\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dbe918b-97db-4e85-97e4-b3b8f52768ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.102  Python-3.9.13 torch-2.6.0+cpu CPU (11th Gen Intel Core(TM) i5-11320H 3.20GHz)\n",
      "YOLOv10n summary (fused): 125 layers, 2,695,586 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "0: 640x640 3 animals, 351.1ms\n",
      "Speed: 29.4ms preprocess, 351.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "from PytorchWildlife.models import detection as pw_detection\n",
    "\n",
    "# Initialize with a valid version (e.g., 'MDV6-yolov10-c')\n",
    "detection_model = pw_detection.MegaDetectorV6(\n",
    "    pretrained=True,\n",
    "    version=\"MDV6-yolov10-c\"  # Choose from the list below\n",
    ")\n",
    "\n",
    "# Run detection\n",
    "img_path2 = \"C:/Users/Roshan Yadav/Downloads/roshan profile photo.jpg\"\n",
    "img_path = \"C:/Users/Roshan Yadav/OneDrive/Desktop/wildlife images/Playful-Leopard-Cub-By-Will-Burrard-Lucas.jpeg\"\n",
    "detection_result = detection_model.single_image_detection(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "27ce580d-cbc9-4a27-b30a-5db1910b37c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_id': 'C:/Users/Roshan Yadav/OneDrive/Desktop/wildlife images/Playful-Leopard-Cub-By-Will-Burrard-Lucas.jpeg',\n",
       " 'detections': Detections(xyxy=array([[     940.65,      2.3651,        1480,      1072.2],\n",
       "        [     490.69,      404.07,      807.65,       786.6],\n",
       "        [     188.46,      672.25,      254.56,      766.67]], dtype=float32), mask=None, confidence=array([    0.96793,     0.92481,     0.23016], dtype=float32), class_id=array([0, 0, 0]), tracker_id=None, data={}),\n",
       " 'labels': ['animal 0.97', 'animal 0.92', 'animal 0.23']}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1230347f-ed7e-4d3a-9b40-3e3a5642c07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Roshan Yadav\\speciesnet-env\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From C:\\Users\\Roshan Yadav\\speciesnet-env\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "From C:\\Users\\Roshan Yadav\\speciesnet-env\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Roshan Yadav\\speciesnet-env\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From C:\\Users\\Roshan Yadav\\speciesnet-env\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "From C:\\Users\\Roshan Yadav\\speciesnet-env\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load SpeciesNet Keras model\n",
    "model_path = \"C:/Users/Roshan Yadav/Downloads/speciesnet-keras-v4.0.0b-v3/full_image_88545560_22x8_v12_epoch_00153.keras\"\n",
    "speciesnet_model = tf.keras.models.load_model(model_path, compile=False)\n",
    "\n",
    "# Load labels of SpeciesNet Keras model\n",
    "labels_path = \"C:/Users/Roshan Yadav/Downloads/speciesnet-keras-v4.0.0b-v3/full_image_88545560_22x8_v12_epoch_00153.labels.txt\"\n",
    "with open(labels_path, 'r') as f:\n",
    "    class_labels = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d9c8a8ab-f7d5-4851-845d-c85f7e8f87d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1856211-cfb7-4a5b-9158-c0f72fd09ee6;;;;;;blank\n"
     ]
    }
   ],
   "source": [
    "for i in class_labels:\n",
    "    if \"blank\" in i:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "550b5f07-f581-4acd-aa5e-743f98f24b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alert configuration\n",
    "ALERT_COOLDOWN = 60  # 1 minute cooldown between alerts for same species\n",
    "last_alert_time = {}\n",
    "\n",
    "def send_alert(species,location):\n",
    "    current_time = time.time()\n",
    "    \n",
    "    # Check if we need to send alert \n",
    "    if (species not in last_alert_time or current_time - last_alert_time[species] > ALERT_COOLDOWN):\n",
    "    \n",
    "        url = \"https://field-project-i1h7.onrender.com//send-alert\" # Replace with your Node.js endpoint\n",
    "        timestamp = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        data = {\n",
    "            \"species\": species,\n",
    "            \"location\" : location,\n",
    "            \"time\" : timestamp\n",
    "        }\n",
    "        try:\n",
    "            response = requests.post(url, json=data)\n",
    "            last_alert_time[species] = current_time\n",
    "            print(f\"[ALERT SENT] {species.capitalize()} â€” Status: {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to send alert: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0360e8d4-e6c4-4e8a-90e3-20b8d4755e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_speciesnet(cropped_img):\n",
    "    \"\"\"Convert OpenCV crop to SpeciesNet's expected format\"\"\"\n",
    "    img = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (480, 480))\n",
    "    img = img / 255.0\n",
    "    return np.expand_dims(img, axis=0)\n",
    "\n",
    "def classify_with_speciesnet(cropped_img):\n",
    "    \"\"\"Run SpeciesNet inference on a cropped image\"\"\"\n",
    "    processed_img = preprocess_for_speciesnet(cropped_img)\n",
    "    preds = speciesnet_model.predict(processed_img, verbose=0)\n",
    "    class_idx = np.argmax(preds[0])\n",
    "    species = class_labels[class_idx].split(\";\")[-1].lower()\n",
    "    return species, float(preds[0][class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12e645d2-24dd-41e9-b85c-62e07e0d3448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 138.1ms\n",
      "Speed: 16.8ms preprocess, 138.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load image\n",
    "img_path = \"C:/Users/Roshan Yadav/OneDrive/Desktop/wildlife images/photo-1575550959106-5a7defe28b56.jpg\"\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# Detection\n",
    "detections = detection_model.single_image_detection(img)\n",
    "\n",
    "# Process detections and draw boxes\n",
    "for box, conf in zip(detections['detections'].xyxy, detections['detections'].confidence):\n",
    "    if conf > 0.5:  # Confidence threshold\n",
    "        x_min, y_min, x_max, y_max = map(int, box)\n",
    "        \n",
    "        # Classification\n",
    "        cropped_img = img[y_min:y_max, x_min:x_max]\n",
    "        species, species_conf = classify_with_speciesnet(cropped_img)\n",
    "        print(f\"Detected {species} (confidence: {species_conf:.2f})\")\n",
    "        \n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(img, (x_min, y_min), (x_max, y_max),(0, 255, 0), 2)\n",
    "        \n",
    "        # Draw label with confidences\n",
    "        label = f\"{species} {conf:.2f}/{species_conf:.2f}\"\n",
    "        cv2.putText(img, label, (x_min, y_min-5), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6,(0, 255, 0), 2)\n",
    "\n",
    "# Display results\n",
    "cv2.imshow(\"Wildlife Detection\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# To save the output:\n",
    "# cv2.imwrite(\"output.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82cc0ca-49a0-4905-a4c6-c31fcfd15eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecb956a2-1188-4f42-89ee-c6095f62540e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'06/04/2025 16:39:23'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f290f70-e5b6-47ad-a19a-2e13b2c83026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 person, 712.2ms\n",
      "Speed: 94.5ms preprocess, 712.2ms inference, 7.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 238.3ms\n",
      "Speed: 8.1ms preprocess, 238.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 208.7ms\n",
      "Speed: 7.0ms preprocess, 208.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 214.6ms\n",
      "Speed: 10.3ms preprocess, 214.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 227.1ms\n",
      "Speed: 9.5ms preprocess, 227.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 213.3ms\n",
      "Speed: 6.8ms preprocess, 213.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 184.6ms\n",
      "Speed: 10.6ms preprocess, 184.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 186.1ms\n",
      "Speed: 6.6ms preprocess, 186.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 vehicle, 202.2ms\n",
      "Speed: 9.5ms preprocess, 202.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 209.6ms\n",
      "Speed: 6.9ms preprocess, 209.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 animal, 192.0ms\n",
      "Speed: 7.9ms preprocess, 192.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 vehicle, 199.0ms\n",
      "Speed: 5.4ms preprocess, 199.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 vehicle, 165.8ms\n",
      "Speed: 7.2ms preprocess, 165.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 vehicle, 188.1ms\n",
      "Speed: 7.5ms preprocess, 188.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 vehicle, 199.1ms\n",
      "Speed: 7.9ms preprocess, 199.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 vehicle, 185.6ms\n",
      "Speed: 7.5ms preprocess, 185.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 213.1ms\n",
      "Speed: 7.3ms preprocess, 213.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 animal, 202.1ms\n",
      "Speed: 6.0ms preprocess, 202.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 person, 168.9ms\n",
      "Speed: 4.6ms preprocess, 168.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 192.7ms\n",
      "Speed: 5.0ms preprocess, 192.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 animal, 189.5ms\n",
      "Speed: 9.6ms preprocess, 189.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 190.3ms\n",
      "Speed: 4.3ms preprocess, 190.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 1 vehicle, 160.6ms\n",
      "Speed: 3.8ms preprocess, 160.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "[ALERT SENT] Jaguar â€” Status: 200\n",
      "\n",
      "0: 640x640 1 animal, 178.0ms\n",
      "Speed: 4.5ms preprocess, 178.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 203.4ms\n",
      "Speed: 5.7ms preprocess, 203.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 187.5ms\n",
      "Speed: 4.7ms preprocess, 187.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 183.8ms\n",
      "Speed: 5.0ms preprocess, 183.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 1 vehicle, 181.3ms\n",
      "Speed: 5.7ms preprocess, 181.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 166.5ms\n",
      "Speed: 4.4ms preprocess, 166.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 168.3ms\n",
      "Speed: 4.4ms preprocess, 168.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 154.0ms\n",
      "Speed: 6.6ms preprocess, 154.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 186.8ms\n",
      "Speed: 4.9ms preprocess, 186.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 154.3ms\n",
      "Speed: 4.2ms preprocess, 154.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 166.8ms\n",
      "Speed: 3.9ms preprocess, 166.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 164.1ms\n",
      "Speed: 4.8ms preprocess, 164.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 1 vehicle, 190.1ms\n",
      "Speed: 4.8ms preprocess, 190.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 152.7ms\n",
      "Speed: 3.9ms preprocess, 152.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 166.4ms\n",
      "Speed: 4.6ms preprocess, 166.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 159.0ms\n",
      "Speed: 4.5ms preprocess, 159.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 1 person, 171.1ms\n",
      "Speed: 4.4ms preprocess, 171.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 160.1ms\n",
      "Speed: 4.8ms preprocess, 160.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 1 person, 158.6ms\n",
      "Speed: 5.8ms preprocess, 158.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 157.3ms\n",
      "Speed: 4.8ms preprocess, 157.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 158.1ms\n",
      "Speed: 4.0ms preprocess, 158.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 1 person, 177.1ms\n",
      "Speed: 4.1ms preprocess, 177.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 155.5ms\n",
      "Speed: 3.9ms preprocess, 155.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "[ALERT SENT] Leopard â€” Status: 200\n",
      "\n",
      "0: 640x640 1 animal, 154.2ms\n",
      "Speed: 4.5ms preprocess, 154.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 2 animals, 169.7ms\n",
      "Speed: 4.8ms preprocess, 169.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 201.1ms\n",
      "Speed: 5.2ms preprocess, 201.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n",
      "\n",
      "0: 640x640 1 animal, 168.6ms\n",
      "Speed: 4.6ms preprocess, 168.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class ID :  0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_skip = 4\n",
    "    frame_id = 0\n",
    "    skip = {\"jaguar\",\"leopard\"}\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        # Process frame\n",
    "        small_frame = cv2.resize(frame, (640, 360))\n",
    "        detections = detection_model.single_image_detection(small_frame)\n",
    "\n",
    "        # Track detected species in current frame\n",
    "        current_species = set()\n",
    "\n",
    "        for box, conf, cls_id in zip(detections['detections'].xyxy, detections['detections'].confidence, detections['detections'].class_id):\n",
    "            if cls_id == 0 and conf > 0.1:  # Only high-confidence detections\n",
    "                print(\"Class ID : \",cls_id)\n",
    "                x_min, y_min, x_max, y_max = map(int, box)\n",
    "                cropped_img = small_frame[y_min:y_max, x_min:x_max]\n",
    "                \n",
    "                if cropped_img.size == 0:\n",
    "                    continue\n",
    "\n",
    "                # Classification\n",
    "                species, species_conf = classify_with_speciesnet(cropped_img)\n",
    "                # if species in skip:\n",
    "                #     continue\n",
    "                current_species.add(species)  # Track unique species\n",
    "\n",
    "                # Visualization\n",
    "                cv2.rectangle(small_frame, (x_min, y_min), (x_max, y_max), (0,255,0), 2)\n",
    "                cv2.putText(small_frame, f\"{species[:12]} {conf:.1f}\", \n",
    "                            (x_min, y_min-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n",
    "                \n",
    "\n",
    "\n",
    "        # Send alerts for detected species\n",
    "        for species in current_species:\n",
    "            if species in skip:\n",
    "                send_alert(species, \"Mumbai\")\n",
    "\n",
    "        # Display\n",
    "        cv2.imshow(\"Wildlife Detection\", small_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        frame_id += frame_skip + 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "path = \"C:/Users/Roshan Yadav/Downloads/videoplayback (1).mp4\"\n",
    "process_video(path)  # 0 for webcam, or path to video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ba66f0-8650-4f19-8bc0-6b5cd3c98a93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68715e3-f026-49f4-8225-25ca34682c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989999b8-27d7-49dd-9592-e1bebbf52c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbd3544-2752-4064-8f11-bf0867f60352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d84a9c-c35f-4c1e-8862-8b384f486002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cc5652-0fe8-46e3-bb62-17f4e10c3675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5379abc-a76d-4f05-b310-c4f843825e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ae9d2b-0df0-44f0-8f1a-6f41a41616eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b466e72-75ab-40d3-b5a3-d3f8193d5be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8afd68e-08f9-4afc-8dae-48067ed1c244",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_skip = 4  # Skip more frames for speed\n",
    "    frame_id = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        # Resize frame for faster processing\n",
    "        frame = cv2.resize(frame, (640, 360))\n",
    "\n",
    "        # Detection\n",
    "        detections = detection_model.single_image_detection(frame)\n",
    "\n",
    "        # Process detections\n",
    "        for box, conf in zip(detections['detections'].xyxy, detections['detections'].confidence):\n",
    "            if conf > 0.5:\n",
    "                x_min, y_min, x_max, y_max = map(int, box)\n",
    "\n",
    "                cropped_img = frame[y_min:y_max, x_min:x_max]\n",
    "                if cropped_img.size == 0:\n",
    "                    continue\n",
    "\n",
    "                species, species_conf = classify_with_speciesnet(cropped_img)\n",
    "\n",
    "                # Draw bounding box\n",
    "                color = (0, 255, 0)\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), color, 2)\n",
    "                label = f\"{species} {conf:.2f}/{species_conf:.2f}\"\n",
    "                cv2.putText(frame, label, (x_min, y_min - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "        # Display smaller preview\n",
    "        cv2.imshow(\"Wildlife Detection\", cv2.resize(frame, (640, 360)))\n",
    "\n",
    "        # Exit on 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Skip next N frames\n",
    "        frame_id += frame_skip + 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "video_path = \"C:/Users/Roshan Yadav/Downloads/videoplayback.mp4\"  # Change to your video path\n",
    "process_video(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dda242-23eb-40ea-87c1-bed233c9e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "executor = ThreadPoolExecutor(max_workers=2)\n",
    "\n",
    "def preprocess_for_speciesnet(cropped_img):\n",
    "    img = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (480, 480))\n",
    "    img = img / 255.0\n",
    "    return np.expand_dims(img, axis=0)\n",
    "\n",
    "def classify_with_speciesnet(cropped_img):\n",
    "    processed_img = preprocess_for_speciesnet(cropped_img)\n",
    "    preds = speciesnet_model.predict(processed_img, verbose=0)\n",
    "    class_idx = np.argmax(preds[0])\n",
    "    species = class_labels[class_idx].split(\";\")[-1].lower()\n",
    "    return species, float(preds[0][class_idx])\n",
    "\n",
    "def process_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_skip = 4  # Process every 3rd frame\n",
    "\n",
    "    future_results = []\n",
    "    species_results = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        for _ in range(frame_skip):\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "        \n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        detections = detection_model.single_image_detection(frame)\n",
    "        species_results.clear()\n",
    "\n",
    "        # Submit classification tasks in parallel\n",
    "        for box, conf in zip(detections['detections'].xyxy, detections['detections'].confidence):\n",
    "            if conf > 0.5:\n",
    "                x_min, y_min, x_max, y_max = map(int, box)\n",
    "                cropped_img = frame[y_min:y_max, x_min:x_max]\n",
    "\n",
    "                if cropped_img.size == 0:\n",
    "                    continue\n",
    "\n",
    "                future = executor.submit(classify_with_speciesnet, cropped_img)\n",
    "                future_results.append((future, box, conf))\n",
    "\n",
    "        # Get results and draw\n",
    "        for future, box, conf in future_results:\n",
    "            species, species_conf = future.result()\n",
    "            x_min, y_min, x_max, y_max = map(int, box)\n",
    "            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "            label = f\"{species} {conf:.2f}/{species_conf:.2f}\"\n",
    "            cv2.putText(frame, label, (x_min, y_min - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        future_results.clear()\n",
    "\n",
    "        cv2.imshow(\"Wildlife Detection\", frame)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "video_path = \"C:/Users/Roshan Yadav/Downloads/videoplayback.mp4\"  # Change to your video path\n",
    "process_video(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13868cdf-474c-4c50-a626-c884ee92873b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a98621-80e4-4d3d-8b76-3380187b9982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79acc01-9fd5-4705-a822-5f715bec1f86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fedb279-01d8-4582-af13-b8d6bae3ef81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a1d494-1430-4b7e-bc3b-8e12c136ec48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90320be-a19a-4dda-b884-c27bb7259df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
